---
title: "EDA_GroupG"
output: html_document
date: "2025-10-13"
Authors: "Oksana Efron, Sabrina Hassan, Keri Gagnow"
---

```{r setup, include=FALSE}
library(readr)
library(psych)
library(corrplot)
library(ggplot2)
library(lavaan)
library(knitr)
```
Importing our dataset into R Markdown:
```{r}
library(readr)

student_depression_dataset_CSV <- read_csv("student_depression_dataset_CSV.csv")

View(student_depression_dataset_CSV)
```
We found a data set that analyzes mental health trends and predictors among students, which we ended up naming to StudentDep. We reorganized the data so it has 70 cases and 17 variables. Our goal was to make sure that the variables was layed out properly and in a better fit so we could analyze.

```{r}
StudentDep <- student_depression_dataset_CSV[1:70, c("Gender", "Age", "City", "Profession", "Academic_Pressure", "Work_Pressure", "CGPA", "Study_Satisfaction", "Job_Satisfaction", "Sleep_Duration", "Dietary_Habits", "Degree", "Suicidal_Thoughts", "Work/Study_Hours", "Financial_Stress", "Family_History_of_Mental_Illness", "Depression")]
dim(StudentDep)
```

```{r}
StudentDep
```
What we did here is converted the categorical variables into numerical form, such as 1 for males and 0 for females. As well as for Dietary Habits and Sleep Duration, they were changed into numeric factors.

```{r}
# Making sure to change Gender to binary so its Males = 1, and Female = 0
StudentDep$Gender <- ifelse(StudentDep$Gender == "Male", 1, 0)
 
# Also doing this for Family History of Mental Illness converting, binary (Yes = 1, No = 0)
StudentDep$Family_History_of_Mental_Illness <- ifelse(StudentDep$Family_History_of_Mental_Illness == "Yes", 1, 0)
 
# Converting ordinal variables for Dietary Habits and Sleep Duration
StudentDep$Dietary_Habits <- as.numeric(factor(StudentDep$Dietary_Habits,
                                                  levels = c("Unhealthy", "Moderate", "Healthy"),
                                                  ordered = TRUE))
StudentDep$Sleep_Duration <- as.numeric(factor(StudentDep$Sleep_Duration,
                                                  levels = c("'Less than 5 hours'", "'5-6 hours'", "'7-8 hours'", "'More than 8 hours'"),
                                                  ordered = TRUE))
 
# Converting Depression, for binary levels. Yes = 1 and No = 0
#StudentDep$Depression <- ifelse(StudentDep$Depression == "Yes", 1, 0)
 
str(StudentDep)


```
```{r}
summary(StudentDep)
```
```{r}
dim(StudentDep)
```
We used boxplot to compare Academic Pressure and Study Satisfaction in  One-Dimensional Graphs
```{r}
ggplot(StudentDep) + geom_bar(aes(x = Academic_Pressure))

ggplot(StudentDep) + geom_bar(aes(x = Study_Satisfaction))
```




For here we made sure to have variables that are predictors, and variables that are response variables.

```{r}
# Predictor Variables
X <- StudentDep[, c("Gender", "Age", "Academic_Pressure", 
                    "CGPA", "Dietary_Habits", "Financial_Stress",
                    "Family_History_of_Mental_Illness")]
# Response Variables
Y <- StudentDep[, c("Depression", "Study_Satisfaction", "Sleep_Duration")]
```
Used summary instead of describe()

```{r}
# Defining skewness and kurtosis
Skewness <- function(x) {
  n <- length(x)
  m3 <- sum((x - mean(x))^3)/n
  s3 <- sd(x)^3
}

kurtosis <- function(x) {
  n <- length(x)
  m4 <- sum((x - mean(x))^4)/n
  s4 <- sd(x)^4
  m4/s4
}


summary(StudentDep)
```
```{r}
# Calculating mean, Standard Deviation, Skewness, and Kurtosis
Vals <- sapply(StudentDep, is.numeric)
Data <- StudentDep[, Vals]

# Removing NA
Data <- Data[, colSums(is.na(Data)) < nrow(Data)]

SumStats <- data.frame(
  variable = colnames(Data),
  Mean = sapply(Data, mean),
  SD = sapply(Data, sd),
  Skewness = sapply(Data, Skewness),
  Kurtosis = sapply(Data, kurtosis)
)
print(SumStats)
```
Finding Covariance, Correlation, Scatter Plot Matrices. A issue faced would be that R is taking binary number that uses for example; Yes = 1, No = 0, into the correlation/covariance which is causing NA to be put into the dataset.

```{r}
# Covariance Matrix
Covar <- cov(Data)
print("Covariance Matrix:")
Covar
```

```{r}
# Correlation Matrix
Corr <- cor(Data, use = "pairwise.complete.obs")
print("Correlation Matrix:")
Corr
```

```{r}
# Scatter Plot
pairs(Data, pch = 19, main = "Scatter Plot")

```
```{r}
# Correlation Plot
corrplot(Corr,na.label = " ", method = "circle")
```
We noticed that there is a strong correlation along the main diagonal of the correlation plot

```{r}
pairs(Data, pch = 19, main = "Scatter matrix for outliers")
```

```{r}
# Mahalanobis distance
Vals <- sapply(Data, is.numeric)
Data <- Data[, Vals]

# Remove
Data <- na.omit(Data)

# Remove columns that have zero variance
Data <- Data[, apply(Data, 2, var) != 0]

center <- colMeans(Data)
Covar <- cov(Data)

mahalDist <- mahalanobis(Data, center, Covar)
Data$mahalanobis <- mahalDist


# Identify Outliers
CutOff <- qchisq(0.975, df = ncol(Data) - 1)
Outliers <- which(mahalDist > CutOff)
Outliers
```

When using the Mahalanobis distance and the use of scattterplots, we wanted to observe the correlation matrix and the outliers. We saw that certain variables may be weaker or stronger which depends between the variables. Also, can see that some extreme data points misshaped the strengths as well the binary variables caused the dataset to not look as appealing.



```{r}
# Predictor Variables
X <- StudentDep[, c("Gender", "Age", "Academic_Pressure", "CGPA", "Dietary_Habits", "Financial_Stress", "Family_History_of_Mental_Illness")]

# Response Variables
Y <- StudentDep[, c("Depression", "Study_Satisfaction", "Job_Satisfaction", "Sleep_Duration")]

# Converting to numeric variables
X[] <- lapply(X, function(col) as.numeric((col)))
Y[] <- lapply(Y, function(col) as.numeric((col)))

# Removing rows with NA
X <- na.omit(X)
Y <- na.omit(Y)

# Keeping columns with zero variance
vars <- sapply(X, var, na.rm = TRUE)
X <- X[, vars > 0]
varsY <- sapply(Y, var, na.rm = TRUE)
Y <- Y[, !is.na(varsY) & varsY > 0]

Y

# Correlation matrices
RX <- cor(X, use = "pairwise.complete.obs")
RY <- cor(Y, use = "pairwise.complete.obs")



# Eigenvalues
EigX <- eigen(RX)
EigY <- eigen(RY)

EigX$values
EigY$values




```

We will be using the Principal Component Analysis to see if an oblique or orthogonal rotation will be necessary for this data set. We will be setting our intrinsic dimensionality to be 3 for both the predictors and response variables
```{r}
R <- pca(r = RX, nfactors = 3, rotate = "varimax")$loadings[]
R1 <- pca(r = RY, nfactors = 3, rotate = "varimax")$loadings[]
print("Orthogonal Rotation :")
R
R1

R_1 <- pca(r = RX, nfactors = 3, rotate = "oblimin")$loadings[]
R_2 <- pca(r = RY, nfactors = 3, rotate = "oblimin")$loadings[]

print("Oblique Rotation :")
R_1
R_2
```
After further analysis of both rotations, we have determined that Orthogonal Rotation will be sufficient in this scenario as the Oblique rotation made the dimensions for the response variables unnecessarily more complex, which the end goal was to reduce the number of complex dimensions with orthogonal or oblique rotation
We will also use correlation plots to visually identify complex dimensions with our rotated loading matrices:
```{r}
corrplot(R, method = "circle")


corrplot(R1, method = "circle")


corrplot(R_1, method = "circle")
```
After visualizing the loading matrices and visualizing them with corrplots, we believe that oblique rotation would not be necessary for this particular data set as the orthogonal rotation and oblique rotation look exactly the same, we no notable differences with complex dimensions. With this in mind, we will be using orthogonal rotation for this data set
```{r}
#Variance 
Var <- (EigX$values / sum(EigX$values)) * 100
Var

CummulVar_f2 <- Var[1] + Var[2]
CummulVar_f2
# Scree Plot 
plot(EigX$values, type = "b", main = "Scree Plot", 
     xlab = "Component", ylab = "Eigenvalue")

# Communalities
communalities <- rowSums(R^2)
communalities
```

Interperting Variance and Covariance:
 We used PCA with a varimax rotation. This analysis gave us 2 main components that together explain 60.46% of the total variance from our four original variables: 
Age, Academic Pressure, CGPA, and Financial Stress. The first component, RC1, primarily represents Academic Pressure and Financial Stress. The second component, RC2, 
is mainly represented by Age and CGPA. We added a scree plot that also agrees with our loadings. The scree plot confirms that two components are optimal, as shown by the 
elbow after the second point where the eigenvalues begin to level off. By using these 2 components, we keep 60.46% of the original information, meaning about 39.54% is lost. 
While this isn't a huge amount of data loss, it is something to watch out for. The communalities tell us how well each variable is captured by the two components. We found 
that CGPA and Academic Pressure are represented the best, while Financial Stress and Age lose a bit more of their unique information. In short, the PCA simplified our four 
variables into two main themes: one for stress factors and one for academic performance.
```{r}
include_graphics(path = "C:/Users/Keri/OneDrive - University of St. Thomas/DASC360 Final Project/DASC360_FinalProject_GroupG/image.png")
```
```{r}
EQN <- '
  # Measurement model (Factor Definition)
  
  DepressionFactor =~ Academic_Pressure + Family_History_of_Mental_Illness + Depression
  Study_SatisfactionFactor =~ Study_Satisfaction + Financial_Stress + Age
  Sleep_DurationFactor =~ Gender + CGPA + Sleep_Duration + Dietary_Habits
  # Measurment Model (Covariance Specification)
  DepressionFactor ~~ Sleep_DurationFactor
  # Structural Model
  Sleep_DurationFactor ~ Study_SatisfactionFactor
'
fit <- sem(EQN, data = Data, std.lv = TRUE)

summary(fit, standardized = TRUE)


```
Identifying and discussing significant predictors and response variables
According to the regression coefficient output from the SEM model, only the statistically significant predictor was detected. Within the measurement model, Study_Satisfaction significantly loaded onto the Study_SatisfactionFactor (Estimate = -0.597, Z = -2.110, P = 0.035), showing that lower levels of reported study satisfaction are associated with higher levels of the latent study satisfaction factor. All other factor loading's such as Academic_Pressure, Family_History_of_Mental_Illness, Depression, Financial_Stress, Age, Gender, CGPA, Sleep_Duration, and Dietary_Habits were not statistically significant, as their p-values were all far above 0.05. In the structural model, Study_SatisfactionFactor did not significantly predict Sleep_DurationFactor (Estimate = 0.102, P = 0.968), illustrating no meaningful relationships between these latent constructs. The covariances among the latent variables were also non-significant (all P > 0.95). Overall, Study_Satisfaction was the only significant predictor in the model, while all other predictors and paths failed to reach statistical significance.

```{r}
fitmeasures(fit)
```
Looking at our fit indices, we will be looking at the MFI, PGFI, RMSEA and NNFI to determine if the fit indices models are a good fit for our original data. 

First starting with our MFI, we can using our 0.90 threshold, we can determine that the MFI model is a good fit for our model as the MFI value of 0.959 is above our threshold, making it a good fit for the data.

Next off is our PGFI, and with the value of 0.525, we can determine that the PGFI is not a good fit for our model as the threshold follows a similar rule of AGFI, which is greater than or equal to 0.9, making the PGFI model not a good fit for our data.

After that is RMSEA and since the RMSEA index encouraging for data to be less than or equal to 0.8, we can determine that RMSEA is a good model fit for our data as our RMSEA value of 0.051 is well below the 0.8 threshold, as smaller is better for this particular model.

Finally NNFI, and following a greater than or equal to threshold of 0.95 and unfortunately NNFI is not a good fit for our model as our NNFI index is 0.813, which is .14 away from meeting the index threshold. Because of that, we can show that NNFI is not a good model fit for our data.
